{"meta":{"title":"Arron's Lab","subtitle":null,"description":null,"author":"a dba's blog","url":"https://arronsh.github.io/lunblog"},"pages":[{"title":"tags","date":"2017-08-12T12:36:45.000Z","updated":"2017-08-12T12:41:20.000Z","comments":true,"path":"tags/index.html","permalink":"https://arronsh.github.io/lunblog/tags/index.html","excerpt":"","text":"[MySQL] [高可用] [压测] [备份恢复][Oracle] [12c]"},{"title":"about","date":"2017-08-12T12:44:16.000Z","updated":"2017-08-12T12:45:41.000Z","comments":true,"path":"about/index.html","permalink":"https://arronsh.github.io/lunblog/about/index.html","excerpt":"","text":"About Me一个小小的DBA"}],"posts":[{"title":"CentOS 7上安装PMM监控MySQL","slug":"install-pmm","date":"2017-12-24T09:08:27.000Z","updated":"2017-12-24T10:20:43.259Z","comments":true,"path":"2017/12/24/install-pmm/","link":"","permalink":"https://arronsh.github.io/lunblog/2017/12/24/install-pmm/","excerpt":"安装PMM监控MySQL（CentOS 7）一、PMM介绍Percona Montoring and Management(PMM)是一款开源的用于管理和监控MySQL和MongoDB性能的开源平台，通过PMM客户端收集到的DB监控数据用第三方软件Grafana画图展示出来。 PMM提供了对MyISAM、InnoDB、TokuDB和PXC/Galera的监控，另外也提供了Query Analytics的功能，可以检视执行了哪些SQL指令，并对执行效能较差的语法进行优化。 PMM针对操作系统的部分也提供了硬盘、网络、CPU和RAM的监控，特别是它提供了Context switches、Processes和interrupts的监控，Conntext Switches可以看到CPU上下切换文的状况，Processes可以方便了解系统有多少程序在等待I/O","text":"安装PMM监控MySQL（CentOS 7）一、PMM介绍Percona Montoring and Management(PMM)是一款开源的用于管理和监控MySQL和MongoDB性能的开源平台，通过PMM客户端收集到的DB监控数据用第三方软件Grafana画图展示出来。 PMM提供了对MyISAM、InnoDB、TokuDB和PXC/Galera的监控，另外也提供了Query Analytics的功能，可以检视执行了哪些SQL指令，并对执行效能较差的语法进行优化。 PMM针对操作系统的部分也提供了硬盘、网络、CPU和RAM的监控，特别是它提供了Context switches、Processes和interrupts的监控，Conntext Switches可以看到CPU上下切换文的状况，Processes可以方便了解系统有多少程序在等待I/O 二、PMM架构解析 PMM Server：Server组件，作为Docker镜像提供的 Query Analytics（QAN）是用来搜集指令并作性能分析的，其组件分别如下： QAN API：作为percona-qan-agent后端储存和读取Query资料用 QAN APP：提供图形化分析界面 Metrics Monitor（MM）组件提供了MySQL和MongoDB历史监控信息，其组件分别如下： Prometheus：一个开源的服务监控系统和时间序列数据库，它连接到PMM Client上的exporter聚集DB的监控数据 Consul：提供API让PMM Client可以远端替Prometheus新增，移除hosts，同时它也储存了监控的metadata。 Grafana：这是一个第三方Dashboard和图形构建器，用于可视化Prometheus中聚合的数据，以web呈现。 Percona Dashboards：是由Percona开发的一组用于Grafana的仪表板 上述的2个Web页面都能从PMM Landing Page（就是PMM首页）直接连结 PMM Client：Client组件，一般以RPM包方式提供 pmm-admin：命令行的PMM Client管理工具，用来新增、移除监控的资料instance percona-qan-agent：用于搜集QAN查询效能性能资料，同时连接和传送资料给PMM Server中的QAN API node_exporter：Prometheus exporter用于收集一般系统信息https://github.com/prometheus/node_exporter。 mysqld_exporter：Prometheus exporter用于收集MySQL Server的信息https://github.com/percona/mysqld_exporter。 mongodb_exporter：Prometheus exporter用于收集MongoDB Server的信息https://github.com/percona/mongodb_exporter。 三、安装PMM ServerPMM Server是使用Docker镜像发布的，首要条件是安装Docker 1.13或更高版本，下面以CentOS 7系统为例说明。 1. 安装Docker使用yum进行安装 123456789101112# step 1: 安装必要的一些系统工具yum install -y yum-utils device-mapper-persistent-data lvm2# Step 2: 添加软件源信息yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo# Step 3: 更新并安装 Docker-CEyum makecache fastyum -y install docker-ce# Step 4: 开启Docker服务service docker start 安装校验 1234567891011121314151617[root@dbsrv1 opt]# docker versionClient: Version: 17.09.1-ce API version: 1.32 Go version: go1.8.3 Git commit: 19e2cf6 Built: Thu Dec 7 22:23:40 2017 OS/Arch: linux/amd64Server: Version: 17.09.1-ce API version: 1.32 (minimum version 1.12) Go version: go1.8.3 Git commit: 19e2cf6 Built: Thu Dec 7 22:25:03 2017 OS/Arch: linux/amd64 Experimental: false 配置Docker镜像加速器 由于网络原因，下载官方镜像的速度超级慢，可以使用阿里云容器Hub服务提供的官方镜像站点来加速官方镜像的下载速度 针对Docker客户端版本大于1.10.0的CentOS用户，可以通过修改daemon配置文件/etc/docker/daemon.json来使用加速器： 12345678mkdir -p /etc/dockertee /etc/docker/daemon.json &lt;&lt;-'EOF'&#123; \"registry-mirrors\": [\"https://0csf00y6.mirror.aliyuncs.com\"]&#125;EOFsystemctl daemon-reloadsystemctl restart docker 说明： 关于加速器的地址，需要登录容器Hub服务申请即可，需要有阿里云账号 2. 获取PMM Server镜像文件1docker pull percona/pmm-server:latest 3. 创建PMM数据容器1234567docker create \\ -v /opt/prometheus/data \\ -v /opt/consul-data \\ -v /var/lib/mysql \\ -v /var/lib/grafana \\ --name pmm-data \\ percona/pmm-server:latest /bin/true 此时容器不运行，它只是存在，以确保你在升级到较新的pmm-server时保留所有PMM数据。不要删除或重新创建此容器，除非你打算清除所有PMM数据并重新开始。 上面的命令执行以下操作： docker create：该命令指示Docker守护程序 -v：该选项初始化数据卷的容器 --name：该选项为你可以用于引用Docker网络中的容器分配一个自定义名称 ercona/pmm-server:latest：是导出容器的镜像名称和版本，latest表示最新版本 /bin/true：是容器运行的命令 4. 运行PMM容器123456docker run -d \\ -p 80:80 \\ --volumes-from pmm-data \\ --name pmm-server \\ --restart always \\ percona/pmm-server:latest 以上的命令执行以下操作： docker run：该命令指示守护程序从镜像运行容器 -d：该选项在分离模式（即后台）中启动容器 -p：该选项映射用于访问PMM服务器Web UI的端口，例如-p 8080:80，如果端口80不可用，则可以使用登录页面映射到端口8080 --volumes-from：该选项从pmm-data容器中装入卷 --name：该选项为你可以用于引用Docker网络中的容器分配一个自定义名称 --restart：该选项定义容器的重新启动策略，设置它以always确保Docker守护程序在启动时启动容器，并在容器退出时重新启动它 percona/pmm-server:latest：是导出容器的镜像名称和版本 5. 验证PMM Server安装查看Docker运行状态 123[root@dbsrv1 opt]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES26a60e9b504f percona/pmm-server:latest \"/opt/entrypoint.sh\" 4 minutes ago Up 4 minutes 0.0.0.0:80-&gt;80/tcp, 443/tcp pmm-server 运行PMM Server之后，可以使用运行容器的主机IP地址(192.168.56.130)访问PMM Web界面。 四、安装PMM ClientPMM Client是安装在你要监视的MySQL或MongoDB主机上的一组代理组件。用于收集关于一般系统和数据库性能的各种数据，并将这些数据发送到相应的PMM服务器组件。 PMM Client可以运行在任何Linux发行版本上，这里已CentOS 7为例。 123# rpm -ivh https://www.percona.com/downloads/pmm-client/LATEST/pmm-client-1.5.3-1.x86_64.rpm # which pmm-admin/usr/sbin/pmm-admin pmm-admin工具用来管理PMM客户端，该工具需要root访问权限。该命令详细用法查看help或官方文档 五、添加MySQL监控1. 连接PMM服务器安装PMM Client之后，它不会自动连接到PMM Server上。要将客户端连接到PMM服务器，请使用下面命令，指定PMM Server的IP地址 123456[root@node1 vagrant]# pmm-admin config --server 192.168.56.130OK, PMM server is alive.PMM Server | 192.168.56.130Client Name | node2Client Address | 192.168.56.111 2. 创建监控账号12345root@localhost:mysql3306.sock [(none)]&gt;grant all on *.* to 'monitor'@'localhost' identified by '123123';Query OK, 0 rows affected, 1 warning (0.01 sec)root@localhost:mysql3306.sock [(none)]&gt;flush privileges;Query OK, 0 rows affected (0.01 sec) 3. 添加MySQL监控和主机监控1234[root@node1 ~]# pmm-admin add mysql --user monitor --password='123123' --host localhost --port 3306[linux:metrics] OK, now monitoring this system.[mysql:metrics] OK, now monitoring MySQL metrics using DSN monitor:***@unix(/tmp/mysql3306.sock)[mysql:queries] OK, now monitoring MySQL queries from slowlog using DSN monitor:***@unix(/tmp/mysql3306.sock) pmm client收集的监控数据来源有这么几个方面： MySQL所在机器的系统指标（linux:meteric） MySQL的performance_schema（mysql:meteric） MySQL慢查询日志（mysql:queries） 查看配置后的结果 1234567891011121314[root@node1 ~]# pmm-admin listpmm-admin 1.5.3PMM Server | 192.168.56.130Client Name | node1Client Address | 192.168.56.110Service Manager | linux-systemd-------------- ------ ----------- -------- -------------------------------------- ------------------------------------------SERVICE TYPE NAME LOCAL PORT RUNNING DATA SOURCE OPTIONS-------------- ------ ----------- -------- -------------------------------------- ------------------------------------------mysql:queries node1 - YES monitor:***@unix(/tmp/mysql3306.sock) query_source=slowlog, query_examples=truelinux:metrics node1 42000 YES -mysql:metrics node1 42002 YES monitor:***@unix(/tmp/mysql3306.sock) 查看exporter监听端口 123[root@node1 ~]# netstat -nlpt|grep exporttcp 0 0 192.168.56.111:42000 0.0.0.0:* LISTEN 5277/node_exportertcp 0 0 192.168.56.111:42002 0.0.0.0:* LISTEN 5312/mysqld_exporte 六、查看监控平台使用运行PMM Server的主机IP访问PMM Web界面，目标网页链接到相应的PMM工具： Component URL 备注 PMM landing page http://192.168.56.130 PMM跳转页 Query Analytics (QAN web app) http://192.168.56.130/qan SQL慢日志分析 Metrics Monitor (Grafana) http://192.168.56.130/graph 监控指标图标，user name:admin, password:admin Orchestrator http://192.168.56.130/orchestrator MySQL集群拓扑结构 1. 指标监控该监控工具提供了对数据库服务器的关键指标，基于时间的图标展示。 通过主题分为若干个仪表板，一些与MySQL或MongoDB相关，其他的则提供了一般的系统指标 要访问仪表板，需要提供默认用户：admin，密码：admin 2. 慢查询分析该查询分析工具，使数据库管理员和应用程序开发人员分析一段时间内的MySQL查询，发现性能问题，优化数据库性能。 PMM使用slow log作为查询源（还可以以performance_schema作为数据源），记得需要开启慢查询日志。 12slow_query_log=1 #开启慢查询日志；long_query_time=0 #超过多少秒的查询就写入日志； 以下图片显示了Query Analytics 汇总表包含以%GTT(总计时间的百分比)排名的前十名查询，这是MySQL服务器执行特定查询所花费的时间百分比，与在所选期间执行所有查询的总时间相比。 在汇总表上单击，可以获取该查询的详细信息，包括该SQL的所有指标，SQL语句示例，explain等 另外查询数据的默认源是慢查询日志，可以调整为Performance Schema。 参考文档 https://www.percona.com/doc/percona-monitoring-and-management/index.html http://www.ywnds.com/?p=9713","categories":[],"tags":[{"name":"pmm","slug":"pmm","permalink":"https://arronsh.github.io/lunblog/tags/pmm/"}]},{"title":"Dataguard故障--MRP进程终止","slug":"datagurad-mrp","date":"2017-08-14T13:29:57.000Z","updated":"2017-08-14T13:33:42.000Z","comments":true,"path":"2017/08/14/datagurad-mrp/","link":"","permalink":"https://arronsh.github.io/lunblog/2017/08/14/datagurad-mrp/","excerpt":"一、现象昨天凌晨DG告警，MRP进程不存在： ***** bsCentreon ***** Notification Type: PROBLEM Service: check_dataguard_mrp Host: db_dg_bs Address: *.*.*.* State: CRITICAL Date/Time: Thu Jul 13 22:59:29 CST 2017 Additional Info: CRITICAL!-DataGuards MRP0 process is crash, please check it!","text":"一、现象昨天凌晨DG告警，MRP进程不存在： ***** bsCentreon ***** Notification Type: PROBLEM Service: check_dataguard_mrp Host: db_dg_bs Address: *.*.*.* State: CRITICAL Date/Time: Thu Jul 13 22:59:29 CST 2017 Additional Info: CRITICAL!-DataGuards MRP0 process is crash, please check it! 二、故障诊断1. 登上DG服务器查看MRP进程:ps -ef|grep mrp 或者 select pid, process, status, sequence#, delay_mins, block#, blocks from v$managed_standby order by sequence#; 都没发现MRP进程的相关信息 2. 查看错误日志$vi alter_xxx.log Thu Jul 13 22:44:22 2017 File #42 added to control file as &apos;UNNAMED00042&apos; because the parameter STANDBY_FILE_MANAGEMENT is set to MANUAL The file should be manually created to continue. MRP0: Background Media Recovery terminated with error 1274 Errors in file /data/app/oracle/diag/rdbms/masadbdgbs/masadb/trace/masadb_pr00_15599.trc: ORA-01274: cannot add datafile &apos;+DATA01/masadb/datafile/ts_part_table4_1.dbf&apos; - file could not be created Managed Standby Recovery not using Real Time Apply Recovery interrupted! Recovered data files to a consistent state at change 5706142969 Thu Jul 13 22:44:24 2017 MRP0: Background Media Recovery process shutdown (masadb) 发现在故障报出的时间点前，MRP进程确实shutdown了。 3. 故障分析 主库上新添加的数据文件+DATA01/masadb/datafile/ts_part_table4_1.dbf没有同步到DG备库上。 再往上看发现这样的字样： 123File #42 added to control file as 'UNNAMED00042' because the parameter STANDBY_FILE_MANAGEMENT is set to MANUAL The file should be manually created to continue. 42号文件由于参数STANDBY_FILE_MANAGEMENT=MANUAL的原因，没有被正确创建，命名为’UNNAMED00042’ 查看相关视图：123456789101112131415SQL&gt; show parameter standby_file_managementNAME TYPE VALUE------------------------------------ ----------- ------------------------------standby_file_management string MANUALSQL&gt; select file_name from dba_data_files where file_id=42;no rows selectedSQL&gt; select name from v$datafile where file#=42;NAME--------------------------------------------------------------------------------/data/app/oracle/product/11.2.0/db_1/dbs/UNNAMED00042 至此已经清楚故障的原因了： 由于standby_file_management=MANUAL，导致主库新添加的数据文件，在传到从库时路径不一致不能自动创建，并命名为’UNNAMED00042’ 由于新数据文件不存在，导致MRP在应用日志是出错而crash。 至于standby_file_management参数，是由于上次维护DG时，将手工设置为MANUAL，方便进行redo log文件的清理。而事后未调整回AUTO所致 4. 处理方案# 注意，该命令执行必须要确保standby_file_management=MANUAL，否则会报错 SQL&gt; ALTER DATABASE CREATE DATAFILE &apos;/data/app/oracle/product/11.2.0/db_1/dbs/UNNAMED00042&apos; as &apos;/data/oradata/masadb/ts_part_table4_1.dbf&apos;; SQL&gt; alter database recover managed standby database using current logfile disconnect from session; 观察日志输出，MRP进程启动，能够正确应用日志 别忘了把参数改回来 ALTER SYSTEM SET standby_file_management=&apos;AUTO&apos;;","categories":[],"tags":[{"name":"dataguard","slug":"dataguard","permalink":"https://arronsh.github.io/lunblog/tags/dataguard/"}]},{"title":"远程机房Dataguard出现GAP问题处理","slug":"datagurad-gap","date":"2017-08-14T13:00:05.000Z","updated":"2017-08-14T13:05:24.000Z","comments":true,"path":"2017/08/14/datagurad-gap/","link":"","permalink":"https://arronsh.github.io/lunblog/2017/08/14/datagurad-gap/","excerpt":"##故障现象远程机房Dataguard告警系统报警出现GAP，登陆备库查看相关视图和日志","text":"##故障现象远程机房Dataguard告警系统报警出现GAP，登陆备库查看相关视图和日志 1234567891011121314151617181920212223242526272829-- 视图查询SQL&gt; select name,value from v$dataguard_stats;NAME VALUE-------------------------------- ----------------------------------------------------------------transport lag +02 00:34:43apply lag +02 00:34:43apply finish time +00 00:01:28.220estimated startup time 17-- 日志查询Fri Jun 03 12:39:10 2016WARN: ARC2: Terminating pid 20229 hung on an I/O operationkrsv_proc_kill: Killing 1 processes (Process by index)Fri Jun 03 12:39:10 2016WARN: ARCH: Terminating pid 20229 hung on an I/O operationWARN: ARCH: Terminating pid 20233 hung on an I/O operationkrsv_proc_kill: Killing 1 processes (Process by index)Fri Jun 03 12:39:15 2016FAL[client]: Failed to request gap sequence GAP - thread 2 sequence 1648-1662 DBID 1666528406 branch 867683567FAL[client]: All defined FAL servers have been attempted.------------------------------------------------------------Check that the CONTROL_FILE_RECORD_KEEP_TIME initializationparameter is defined to a value that`s sufficiently largeenough to maintain adequate log switch information to resolvearchivelog gaps.------------------------------------------------------------ ##原因分析由于前两天在主库上多几张大表（包括CLOB）进行处理，转移到历史表中，产生了大量的归档日志（超过80G），而远程机房是通过2M专线与本地机房相连，大日志传输到备机需要时间超时，导致DG无法正常完成归档日志的接收，进而出现归档日志的GAP。解决gap的步骤： 在备库获得gap的详细信息 将需要的归档日志从主库拷贝到备库 备库将归档日志注册，然后应用。 ##处理方法 停止归档日志对远程机房DG的传输 123456SQL&gt; alter system set log_archive_dest_state_3='defer' sid='*';SQL&gt; show parameter log_archive_dest_state_3;NAME TYPE VALUE------------------------------------ ----------- ------------------------------log_archive_dest_state_3 string defer 查询备库缺失的归档日志 12345SQL&gt; select thread#, low_sequence#, high_sequence# from v$archive_gap; THREAD# LOW_SEQUENCE# HIGH_SEQUENCE#---------- ------------- -------------- 2 1648 1662 组装归档日志的拷贝语句如果归档日志在ASM中，先通过rman将归档日志拷贝到OS，然后scp到备库standby归档目录；如果归档日志在OS上，直接scp到备库standby归档目录即可。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950-- 主库--生产rman用的日志拷贝命令select 'copy archivelog ''' || NAME || ''' to ''/tmp/' || substr(name, 43,1)||'_'|| substr(name, 49,4) ||'_867683567.dbf'' ;' from v$archived_log where sequence# &gt;= 1648 and sequence# &lt;= 1662 and thread# = 2 and dest_id = 1; -- 把归档日志从ASM拷贝到OS上rman target /copy archivelog '+ARCH/masadb/archivelog/2016_06_01/thread_2_seq_1648.522.913378253' to '/tmp/2_1648_867683567.dbf' ;copy archivelog '+ARCH/masadb/archivelog/2016_06_01/thread_2_seq_1649.523.913378315' to '/tmp/2_1649_867683567.dbf' ;copy archivelog '+ARCH/masadb/archivelog/2016_06_01/thread_2_seq_1650.524.913378361' to '/tmp/2_1650_867683567.dbf' ;copy archivelog '+ARCH/masadb/archivelog/2016_06_01/thread_2_seq_1651.526.913378391' to '/tmp/2_1651_867683567.dbf' ;copy archivelog '+ARCH/masadb/archivelog/2016_06_01/thread_2_seq_1652.527.913378427' to '/tmp/2_1652_867683567.dbf' ;copy archivelog '+ARCH/masadb/archivelog/2016_06_01/thread_2_seq_1653.528.913378465' to '/tmp/2_1653_867683567.dbf' ;copy archivelog '+ARCH/masadb/archivelog/2016_06_01/thread_2_seq_1654.530.913378517' to '/tmp/2_1654_867683567.dbf' ;copy archivelog '+ARCH/masadb/archivelog/2016_06_01/thread_2_seq_1655.531.913378585' to '/tmp/2_1655_867683567.dbf' ;copy archivelog '+ARCH/masadb/archivelog/2016_06_01/thread_2_seq_1656.532.913378675' to '/tmp/2_1656_867683567.dbf' ;copy archivelog '+ARCH/masadb/archivelog/2016_06_01/thread_2_seq_1657.535.913379177' to '/tmp/2_1657_867683567.dbf' ;copy archivelog '+ARCH/masadb/archivelog/2016_06_01/thread_2_seq_1658.536.913379305' to '/tmp/2_1658_867683567.dbf' ;copy archivelog '+ARCH/masadb/archivelog/2016_06_01/thread_2_seq_1659.537.913379423' to '/tmp/2_1659_867683567.dbf' ;copy archivelog '+ARCH/masadb/archivelog/2016_06_01/thread_2_seq_1660.539.913379583' to '/tmp/2_1660_867683567.dbf' ;copy archivelog '+ARCH/masadb/archivelog/2016_06_01/thread_2_seq_1661.541.913381163' to '/tmp/2_1661_867683567.dbf' ;copy archivelog '+ARCH/masadb/archivelog/2016_06_01/thread_2_seq_1662.542.913381281' to '/tmp/2_1662_867683567.dbf' ;-- 在主库上执行，生成standby上需要的归档日志注册语句select 'ALTER DATABASE REGISTER PHYSICAL LOGFILE ''/tmp/' || substr(name, 43,1)||'_'|| substr(name, 49,4) ||'_867683567.dbf'';' from v$archived_log where sequence# &gt;= 1648 and sequence# &lt;= 1662 and thread# = 2 and dest_id = 1;ALTER DATABASE REGISTER PHYSICAL LOGFILE '/tmp/2_1648_867683567.dbf';ALTER DATABASE REGISTER PHYSICAL LOGFILE '/tmp/2_1649_867683567.dbf';ALTER DATABASE REGISTER PHYSICAL LOGFILE '/tmp/2_1650_867683567.dbf';ALTER DATABASE REGISTER PHYSICAL LOGFILE '/tmp/2_1651_867683567.dbf';ALTER DATABASE REGISTER PHYSICAL LOGFILE '/tmp/2_1652_867683567.dbf';ALTER DATABASE REGISTER PHYSICAL LOGFILE '/tmp/2_1653_867683567.dbf';ALTER DATABASE REGISTER PHYSICAL LOGFILE '/tmp/2_1654_867683567.dbf';ALTER DATABASE REGISTER PHYSICAL LOGFILE '/tmp/2_1655_867683567.dbf';ALTER DATABASE REGISTER PHYSICAL LOGFILE '/tmp/2_1656_867683567.dbf';ALTER DATABASE REGISTER PHYSICAL LOGFILE '/tmp/2_1657_867683567.dbf';ALTER DATABASE REGISTER PHYSICAL LOGFILE '/tmp/2_1658_867683567.dbf';ALTER DATABASE REGISTER PHYSICAL LOGFILE '/tmp/2_1659_867683567.dbf';ALTER DATABASE REGISTER PHYSICAL LOGFILE '/tmp/2_1660_867683567.dbf';ALTER DATABASE REGISTER PHYSICAL LOGFILE '/tmp/2_1661_867683567.dbf';ALTER DATABASE REGISTER PHYSICAL LOGFILE '/tmp/2_1662_867683567.dbf'; 拷贝归档日志到远程DG上 123456789101112131415161718192021-- 网络环境理想，文件不大的话用scp$ scp 2_16* oracle@10.1.1.10:/tmp-- 网络环境差，经常会断线的话，可以使用rsync（支持断点续传）-- 自定义脚本[oracle@DB_DG_BS ~]$ cat rsync_cp.sh #!/bin/bash# rsync_cp.shexport RSYNC_RSH=\"ssh -o ServerAliveInterval=15 -o ServerAliveCountMax=2\"rsyncSrcFile=$1rsyncDestFile=$2rsyncSuccess=-1while [ $rsyncSuccess -ne 0 ]do rsync -v -P --partial --inplace $rsyncSrcFile $rsyncDestFile rsyncSuccess=$?done-- 调用脚本$./rsync_cp.sh oracle@10.11.60.15:/tmp/2_1648_867683567.dbf /data/arch/masadb/ 备库上执行前面生成的归档日志注册语句 123456789101112131415ALTER DATABASE REGISTER PHYSICAL LOGFILE '/tmp/2_1648_867683567.dbf';ALTER DATABASE REGISTER PHYSICAL LOGFILE '/tmp/2_1649_867683567.dbf';ALTER DATABASE REGISTER PHYSICAL LOGFILE '/tmp/2_1650_867683567.dbf';ALTER DATABASE REGISTER PHYSICAL LOGFILE '/tmp/2_1651_867683567.dbf';ALTER DATABASE REGISTER PHYSICAL LOGFILE '/tmp/2_1652_867683567.dbf';ALTER DATABASE REGISTER PHYSICAL LOGFILE '/tmp/2_1653_867683567.dbf';ALTER DATABASE REGISTER PHYSICAL LOGFILE '/tmp/2_1654_867683567.dbf';ALTER DATABASE REGISTER PHYSICAL LOGFILE '/tmp/2_1655_867683567.dbf';ALTER DATABASE REGISTER PHYSICAL LOGFILE '/tmp/2_1656_867683567.dbf';ALTER DATABASE REGISTER PHYSICAL LOGFILE '/tmp/2_1657_867683567.dbf';ALTER DATABASE REGISTER PHYSICAL LOGFILE '/tmp/2_1658_867683567.dbf';ALTER DATABASE REGISTER PHYSICAL LOGFILE '/tmp/2_1659_867683567.dbf';ALTER DATABASE REGISTER PHYSICAL LOGFILE '/tmp/2_1660_867683567.dbf';ALTER DATABASE REGISTER PHYSICAL LOGFILE '/tmp/2_1661_867683567.dbf';ALTER DATABASE REGISTER PHYSICAL LOGFILE '/tmp/2_1662_867683567.dbf'; 如果备库打开实时应用，则会自动应用归档文件。若未打开，则在备库上使用下面命令： 1ALTER DATABASE RECOVER MANAGED STANDBY DATABASE USING CURRENT LOGFILE DISCONNECT FROM SESSION; 查看实时应用情况 123456789101112-- 通过视图set linesize 200col name for a70alter session set nls_date_format='yyyy-mm-dd hh24:mi:ss';select NAME,THREAD#,FIRST_TIME,sequence#,applied from v$archived_log order by FIRST_TIME,THREAD#,sequence#,DEST_ID;-- 通过alert.log，出现下面类似的语句说明归档日志已经应用了$ tail -f alertxxx.log...Sun Jun 05 06:01:16 2016Media Recovery Log /data/arch/masadb/2_1648_867683567.dbf... 检查视图或者观察alert.log，是否还有GAP存在，有的话重复上面的步骤直到全部处理GAP。 123456789-- 视图SQL&gt; select * from v$archive_gap;-- alert日志...FAL[client]: Failed to request gap sequence GAP - thread 2 sequence 1674-1675 DBID 1666528406 branch 867683567.... 在主库上开启远程备库传输参数 123456SQL&gt; alter system set log_archive_dest_state_3='enable' sid='*';SQL&gt; show parameter log_archive_dest_state_3;NAME TYPE VALUE------------------------------------ ----------- ------------------------------log_archive_dest_state_3 string enable 在主库上，删除多余的拷贝 123456cd /tmprm thread_*RMAN&gt; crosscheck archivelog all;RMAN&gt; list archivelog all;RMAN&gt; delete expired archivelog all;","categories":[],"tags":[{"name":"dataguard","slug":"dataguard","permalink":"https://arronsh.github.io/lunblog/tags/dataguard/"}]},{"title":"ClickHouse安装","slug":"clickhouse-1","date":"2017-08-12T13:06:30.000Z","updated":"2017-08-14T13:01:03.000Z","comments":true,"path":"2017/08/12/clickhouse-1/","link":"","permalink":"https://arronsh.github.io/lunblog/2017/08/12/clickhouse-1/","excerpt":"目前ClickHouse对ubuntu系统支持比较友好，对于centos就差一点。Ubuntu有deb包可以直接安装。对于centos的则需要自己编译。","text":"目前ClickHouse对ubuntu系统支持比较友好，对于centos就差一点。Ubuntu有deb包可以直接安装。对于centos的则需要自己编译。 一、安装准备1. 升级gcc编译ClickHouse需要gcc 6.0以上版本，这里安装6.2.0版本。具体步骤记录如下： 1.1 下载 gcc-6.2.0 源码包, 并解压[root@node1 software]# wget http://ftp.gnu.org/gnu/gcc/gcc-6.2.0/gcc-6.2.0.tar.bz2 [root@node1 software]# tar -jvxf gcc-6.2.0.tar.bz2 [root@node1 software]# cd gcc-6.2.0/ [root@node1 contrib]# vim contrib/download_prerequisites 从 contrib/download_prerequisites 文件内查看需要的依赖包 1.2 下载依赖包[root@node1 software]# wget ftp://gcc.gnu.org/pub/gcc/infrastructure/mpfr-2.4.2.tar.bz2 [root@node1 software]# wget ftp://gcc.gnu.org/pub/gcc/infrastructure/gmp-4.3.2.tar.bz2 [root@node1 software]# wget ftp://gcc.gnu.org/pub/gcc/infrastructure/mpc-0.8.1.tar.gz 1.3 安装gmp[root@node1 software]# bzip2 -d gmp-4.3.2.tar.bz2 [root@node1 software]# tar xvf gmp-4.3.2.tar [root@node1 software]# cd gmp-4.3.2/ [root@node1 gmp-4.3.2]# ./configure --prefix=/opt/gcc-6.2.0 [root@node1 gmp-4.3.2]# make &amp;&amp; make install 1.4 安装mpfr[root@node1 gmp-4.3.2]# cd .. [root@node1 software]# bzip2 -d mpfr-2.4.2.tar.bz2 [root@node1 software]# tar xvf mpfr-2.4.2.tar [root@node1 software]# cd mpfr-2.4.2/ [root@node1 mpfr-2.4.2]# ./configure --prefix=/opt/gcc-6.2.0 --with-gmp=/opt/gcc-6.2.0 [root@node1 mpfr-2.4.2]# make -j [root@node1 mpfr-2.4.2]# make install 1.5 安装mpc[root@node1 mpfr-2.4.2]# cd .. [root@node1 software]# tar xvf mpc-0.8.1.tar.gz [root@node1 software]# cd mpc-0.8.1/ [root@node1 mpc-0.8.1]# ./configure --prefix=/opt/gcc-6.2.0 --with-gmp=/opt/gcc-6.2.0 --with-mpfr=/opt/gcc-6.2.0 [root@node1 mpc-0.8.1]# make -j [root@node1 mpc-0.8.1]# make install 1.6 安装gcc[root@node1 mpc-0.8.1]# cd .. [root@node1 software]# cd gcc-6.2.0/ [root@node1 gcc-6.2.0]# mkdir build [root@node1 gcc-6.2.0]# cd build/ [root@node1 build]# ../configure --prefix=/opt/gcc-6.2.0 --with-gmp=/opt/gcc-6.2.0 --with-mpfr=/opt/gcc-6.2.0 --with-mpc=/opt/gcc-6.2.0 -enable-checking=release -enable-languages=c,c++ -disable-multilib [root@node1 build]# make [root@node1 build]# make install 注意：编译过程中可能会出现类似下面的错误： checking for suffix of object files... configure: error: cannot compute suffix of object files: cannot compile See `config.log&apos; for more details. make[2]: *** [configure-stage1-target-libgcc] Error 1 解决方法：将gmp,mpfr,mpc的lib库添加到下面的配置文件中 vi /etc/ld.so.conf include ld.so.conf.d/*.conf /usr/local/lib /opt/gcc-6.2.0/lib #gmp,mpfr,mpc的lib库安装位置 /usr/lib64 添加保存后记得更新动态库的缓存： # ldconfig -v 更新后再去重新编译安装。 1.7 设置环境变量[root@node1 software]# export PATH=/opt/gcc-6.2.0/bin:$PATH [root@node1 software]# export LD_LIBRARY_PATH=/opt/gcc-6.2.0/lib:$LD_LIBRARY_PATH 1.8 查看gcc版本[root@node1 ~]# gcc -v 1.9 创建软链和环境变量[root@node1 ~]# ln -s /usr/local/bin/gcc /usr/local/bin/gcc-6 [root@node1 ~]# ln -s /usr/local/bin/g++ /usr/local/bin/g++-6 [root@node1 ~]# ln -s /usr/local/bin/gcc /usr/local/bin/cc [root@node1 ~]# ln -s /usr/local/bin/g++ /usr/local/bin/c++ [root@node1 ~]# export CC=gcc-6 [root@node1 ~]# export CXX=g++-6 2. 安装其他库依赖包[root@node1 ~]# yum install libicu-devel readline-devel openssl-devel mysql-community-devel unixODBC-devel libtool-ltdl-devel 二、安装ClickHouse1. 下载源码[root@node1 software]# git clone -b stable https://github.com/yandex/ClickHouse.git [root@node1 software]# cd ClickHouse 2. 编译源码mkdir build cd build cmake .. make -j $THREADS make install 注意： 在编译过程中发现对内存的消耗比较大，本人虚机开始配置1G内存，编译时经常莫名的中断报错，后查/var/log/message发现出现OOM情况，后把内存加大到4G，能够正常完成编译 三、简单使用1. 启动clickhouse[root@node1 ~]# /usr/local/bin/clickhouse-server --config-file=/usr/local/etc/clickhouse-server/config.xml &amp; 2. 登录测试[root@node1 ~]# clickhouse-client ClickHouse client version 1.1.54245. Connecting to localhost:9000. Connected to ClickHouse server version 1.1.54245. :) select 1; SELECT 1 ┌─1─┐ │ 1 │ └───┘ 1 rows in set. Elapsed: 0.002 sec. :) select now(); SELECT now() ┌───────────────now()─┐ │ 2017-08-09 23:27:30 │ └─────────────────────┘ 1 rows in set. Elapsed: 0.001 sec. :) 3. 客户端使用3.1 交互模式clickhouse-client clickhouse-client --host=... --port=... --user=... --password=... 3.2 启动多行查询clickhouse-client -m 对于使用多行建表语句进行建表的时候就需要启用多行查询，否则会报错 3.3 以批处理方式运行查询clickhouse-client --query=&apos;SELECT 1&apos; echo &apos;SELECT 1&apos; | clickhouse-client 3.4 从指定格式的文件插入数据clickhouse-client --query=&apos;INSERT INTO table VALUES&apos; &lt; data.txt clickhouse-client --query=&apos;INSERT INTO table FORMAT TabSeparated&apos; &lt; data.tsv 四、参考资料 Column Store Database Benchmarks: MariaDB ColumnStore vs. Clickhouse vs. Apache Spark ClickHouse: New Open Source Columnar Database 彪悍开源的分析数据库-ClickHouse How to build ClickHouse on Linux ClickHouse之初步认识","categories":[],"tags":[{"name":"clickhouse","slug":"clickhouse","permalink":"https://arronsh.github.io/lunblog/tags/clickhouse/"}]},{"title":"Hello World","slug":"hello-world","date":"2017-08-12T07:41:49.000Z","updated":"2017-08-12T07:41:49.000Z","comments":true,"path":"2017/08/12/hello-world/","link":"","permalink":"https://arronsh.github.io/lunblog/2017/08/12/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}